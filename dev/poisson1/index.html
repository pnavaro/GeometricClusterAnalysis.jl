<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>One-dimensional data from the Poisson distribution · GeometricClusterAnalysis.jl</title><meta name="title" content="One-dimensional data from the Poisson distribution · GeometricClusterAnalysis.jl"/><meta property="og:title" content="One-dimensional data from the Poisson distribution · GeometricClusterAnalysis.jl"/><meta property="twitter:title" content="One-dimensional data from the Poisson distribution · GeometricClusterAnalysis.jl"/><meta name="description" content="Documentation for GeometricClusterAnalysis.jl."/><meta property="og:description" content="Documentation for GeometricClusterAnalysis.jl."/><meta property="twitter:description" content="Documentation for GeometricClusterAnalysis.jl."/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img src="../assets/logo.png" alt="GeometricClusterAnalysis.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../">GeometricClusterAnalysis.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Documentation</a></li><li><a class="tocitem" href="../fake_data/">Datasets</a></li><li><a class="tocitem" href="../fleas/">Fleas dataset</a></li><li><a class="tocitem" href="../three_curves/">Three Curves</a></li><li><a class="tocitem" href="../two_spirals/">Two Spirals</a></li><li><a class="tocitem" href="../fourteen_lines/">Fourteen lines</a></li><li><span class="tocitem">Trimmed Bregman Clustering</span><ul><li><a class="tocitem" href="../trimmed-bregman/">Bregman divergences</a></li><li class="is-active"><a class="tocitem" href>One-dimensional data from the Poisson distribution</a><ul class="internal"><li><a class="tocitem" href="#Generation-of-variables-from-a-mixture-of-Poisson-distributions"><span>Generation of variables from a mixture of Poisson distributions</span></a></li><li><a class="tocitem" href="#Data-clustering-on-an-example"><span>Data clustering on an example</span></a></li><li><a class="tocitem" href="#Performance-comparison"><span>Performance comparison</span></a></li><li><a class="tocitem" href="#Selection-of-the-parameters-k-and-\\alpha"><span>Selection of the parameters <span>$k$</span> and <span>$\alpha$</span></span></a></li></ul></li><li><a class="tocitem" href="../poisson2/">Two-dimensional data from the Poisson distribution</a></li><li><a class="tocitem" href="../obama/">Application to authors texts clustering</a></li></ul></li><li><a class="tocitem" href="../dtm/">Robust approximations of compact sets</a></li><li><a class="tocitem" href="../types/">Types</a></li><li><a class="tocitem" href="../functions/">Functions</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Trimmed Bregman Clustering</a></li><li class="is-active"><a href>One-dimensional data from the Poisson distribution</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>One-dimensional data from the Poisson distribution</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/pnavaro/GeometricClusterAnalysis.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/pnavaro/GeometricClusterAnalysis.jl/blob/master/docs/src/poisson1.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="One-dimensional-data-from-the-Poisson-distribution"><a class="docs-heading-anchor" href="#One-dimensional-data-from-the-Poisson-distribution">One-dimensional data from the Poisson distribution</a><a id="One-dimensional-data-from-the-Poisson-distribution-1"></a><a class="docs-heading-anchor-permalink" href="#One-dimensional-data-from-the-Poisson-distribution" title="Permalink"></a></h1><h2 id="Generation-of-variables-from-a-mixture-of-Poisson-distributions"><a class="docs-heading-anchor" href="#Generation-of-variables-from-a-mixture-of-Poisson-distributions">Generation of variables from a mixture of Poisson distributions</a><a id="Generation-of-variables-from-a-mixture-of-Poisson-distributions-1"></a><a class="docs-heading-anchor-permalink" href="#Generation-of-variables-from-a-mixture-of-Poisson-distributions" title="Permalink"></a></h2><p>The function <code>sample_poisson</code> generates random variables according to a mixture of <span>$k$</span> Poisson distributions in dimension <span>$d$</span>. The parameters  are given in the <span>$k\times d$</span>-matrix <code>lambdas</code>. The probabilities of the mixture components are given in the vector <code>proba</code>.</p><p>The function <code>sample_outliers</code> generates random variable uniformly on the hypercube <span>$[0,L]^d$</span>. This function will be used to generate outliers.</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricClusterAnalysis.sample_poisson" href="#GeometricClusterAnalysis.sample_poisson"><code>GeometricClusterAnalysis.sample_poisson</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">sample_poisson(rng, n, d, lambdas, proba)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/pnavaro/GeometricClusterAnalysis.jl/blob/14fc35df6337e6ce817ae110d40482c846311041/src/poisson.jl#L7-L9">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricClusterAnalysis.sample_outliers" href="#GeometricClusterAnalysis.sample_outliers"><code>GeometricClusterAnalysis.sample_outliers</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">sample_outliers(rng, n_outliers, d; scale = 1)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/pnavaro/GeometricClusterAnalysis.jl/blob/14fc35df6337e6ce817ae110d40482c846311041/src/poisson.jl#L22-L24">source</a></section></article><p>We generate a first sample of 950 points from the Poisson distribution with parameters <span>$10$</span>, <span>$20$</span> or <span>$40$</span> with probability <span>$\frac13$</span>. Then, we generate 50 outliers from the uniform distribution on <span>$[0,120]$</span>. We denote by <code>x</code> the resulting sample.</p><pre><code class="language-julia hljs">using GeometricClusterAnalysis
import GeometricClusterAnalysis: sample_poisson, sample_outliers, performance
using Plots
using Random

n = 1000
n_outliers = 50
d = 1

rng = MersenneTwister(1)
lambdas =  [10,20,40]
proba = [1/3,1/3,1/3]
points, labels = sample_poisson(rng, n - n_outliers, d, lambdas, proba)

outliers = sample_outliers(rng, n_outliers, 1; scale = 120)

x = hcat(points, outliers)
labels_true = vcat(labels, zeros(Int, n_outliers))
scatter( x[1,:], c = labels_true, palette = :rainbow)</code></pre><img src="5e31ea5b.svg" alt="Example block output"/><h2 id="Data-clustering-on-an-example"><a class="docs-heading-anchor" href="#Data-clustering-on-an-example">Data clustering on an example</a><a id="Data-clustering-on-an-example-1"></a><a class="docs-heading-anchor-permalink" href="#Data-clustering-on-an-example" title="Permalink"></a></h2><p>In order to cluster the data, we will use the following parameters.</p><pre><code class="language-julia hljs">k = 3 # Number of clusters in the clustering
alpha = 0.04 # Proportion of outliers
maxiter = 50 # Maximal number of iterations
nstart = 20 # Number of initialisations of the algorithm (the best result is kept)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">20</code></pre><h3 id="Using-the-classical-algorithm-:-Trimmed-k-means-[Cuesta-Albertos1997](@cite)"><a class="docs-heading-anchor" href="#Using-the-classical-algorithm-:-Trimmed-k-means-[Cuesta-Albertos1997](@cite)">Using the classical algorithm : Trimmed <span>$k$</span>-means (<a href="../references/#Cuesta-Albertos1997">Cuesta-Albertos <em>et al.</em>, 1997</a>)</a><a id="Using-the-classical-algorithm-:-Trimmed-k-means-[Cuesta-Albertos1997](@cite)-1"></a><a class="docs-heading-anchor-permalink" href="#Using-the-classical-algorithm-:-Trimmed-k-means-[Cuesta-Albertos1997](@cite)" title="Permalink"></a></h3><p>Firstly, we use our algorithm <a href="../trimmed-bregman/#GeometricClusterAnalysis.trimmed_bregman_clustering"><code>trimmed_bregman_clustering</code></a> with the squared Euclidean distance <a href="../functions/#GeometricClusterAnalysis.euclidean-Tuple{Any, Any}"><code>euclidean</code></a>.</p><pre><code class="language-julia hljs">tb_kmeans = trimmed_bregman_clustering(rng, x, k, alpha, euclidean, maxiter, nstart)
tb_kmeans.centers</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">1×3 Matrix{Float64}:
 22.116  40.9987  10.3412</code></pre><p>This method corresponds to the Trimmed <span>$k$</span>-means of (<a href="../references/#Cuesta-Albertos1997">Cuesta-Albertos <em>et al.</em>, 1997</a>).</p><p>We see three clusters with the same diameter. In particular, the group centered at <span>$10$</span> also contains points of the group centered at <span>$20$</span>. Therefore, the estimators <code>tB_kmeans.centers</code> of the three means are not that satisfying. These estimated means are larger than the true means <span>$10$</span>, <span>$20$</span> and <span>$40$</span>.</p><pre><code class="language-julia hljs">plot(tb_kmeans)</code></pre><img src="d394d948.svg" alt="Example block output"/><h3 id="Bregman-divergence-selection-for-the-Poisson-distribution"><a class="docs-heading-anchor" href="#Bregman-divergence-selection-for-the-Poisson-distribution">Bregman divergence selection for the Poisson distribution</a><a id="Bregman-divergence-selection-for-the-Poisson-distribution-1"></a><a class="docs-heading-anchor-permalink" href="#Bregman-divergence-selection-for-the-Poisson-distribution" title="Permalink"></a></h3><p>When using the Bregman divergence associated to the Poisson distribution, the clusters have various diameters. These diameters are well suited for the data. Moreover, the estimators <code>tB_Poisson$centers</code> of the means are better.</p><pre><code class="language-julia hljs">tb_poisson = trimmed_bregman_clustering(rng, x, k, alpha, poisson, maxiter, nstart)
tb_poisson.centers</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">1×3 Matrix{Float64}:
 40.7604  20.6136  9.71071</code></pre><pre><code class="language-julia hljs">plot(tb_poisson)</code></pre><img src="3c4b7ac5.svg" alt="Example block output"/><h2 id="Performance-comparison"><a class="docs-heading-anchor" href="#Performance-comparison">Performance comparison</a><a id="Performance-comparison-1"></a><a class="docs-heading-anchor-permalink" href="#Performance-comparison" title="Permalink"></a></h2><p>We measure the performance of the two clustering methods (with the squared Euclidean distance and with the Bregman divergence associated to the Poisson distribution), using the normalised mutual information (NMI).</p><p>For the Trimmed <code>k</code>-means (that is, with the squared Euclidean distance):</p><pre><code class="language-julia hljs">import Clustering: mutualinfo

println(mutualinfo(labels_true,tb_kmeans.cluster, normed = true))</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">0.641631775173803</code></pre><p>For the trimmed clustering method with the Bregman divergence associated to the Poisson distribution :</p><pre><code class="language-julia hljs">println(mutualinfo(labels_true,tb_poisson.cluster, normed = true))</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">0.6826165935516633</code></pre><p>The normalised mutual information is larger for the Bregman divergence associated to the Poisson distribution. This illustrates the fact that, for this example, using the correct divergence improves the clustering : the performance is better than for a classical trimmed <code>k</code>-means.</p><h3 id="Performance-measurement"><a class="docs-heading-anchor" href="#Performance-measurement">Performance measurement</a><a id="Performance-measurement-1"></a><a class="docs-heading-anchor-permalink" href="#Performance-measurement" title="Permalink"></a></h3><p>In order to ensure that the method with the correct Bregman divergence outperforms Trimmed <code>k</code>-means, we replicate the experiment <code>replications</code> times.</p><p>In particular, we replicate the algorithm <a href="../trimmed-bregman/#GeometricClusterAnalysis.trimmed_bregman_clustering"><code>trimmed_bregman_clustering</code></a>,  <code>replications</code> times, on samples of size <span>$n = 1000$</span>, on data generated according to the aforementionned procedure.</p><p>The function <a href="../functions/#GeometricClusterAnalysis.performance"><code>performance</code></a> does it.</p><pre><code class="language-julia hljs">sample_generator = (rng, n) -&gt; sample_poisson(rng, n, d, lambdas, proba)
outliers_generator = (rng, n) -&gt; sample_outliers(rng, n, d; scale = 120)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">#3 (generic function with 1 method)</code></pre><p>Default values: <code>maxiter = 100, nstart = 10, replications = 100</code></p><pre><code class="language-julia hljs">n = 1200
n_outliers = 200
k = 3
alpha = 0.1
nmi_kmeans, _, _ = performance(n, n_outliers, k, alpha, sample_generator, outliers_generator, euclidean)
nmi_poisson, _, _ = performance(n, n_outliers, k, alpha, sample_generator, outliers_generator, poisson)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">([0.5839398784033235, 0.6202318416861812, 0.6101178140792, 0.6374897347566113, 0.6540671777145892, 0.6083343936925494, 0.6304838453433942, 0.6306156841785864, 0.6336810374826111, 0.6527637354246719  …  0.6248676870772997, 0.6257423603470843, 0.6304698035282263, 0.6376606605106416, 0.6270816412278291, 0.6273014539714742, 0.6195508045521951, 0.6298634762917615, 0.6471578693973343, 0.6209459002804606], 0.6300521037537219, 0.003665377094835531)</code></pre><p>The boxplots show the NMI on the two different methods. The method using the Bregman divergence associated to the Poisson distribution outperfoms the Trimmed <code>k</code>-means method.</p><pre><code class="language-julia hljs">using StatsPlots

boxplot( ones(100), nmi_kmeans, label = &quot;kmeans&quot; )
boxplot!( fill(2, 100), nmi_poisson, label = &quot;poisson&quot; )</code></pre><img src="26092bbb.svg" alt="Example block output"/><h2 id="Selection-of-the-parameters-k-and-\\alpha"><a class="docs-heading-anchor" href="#Selection-of-the-parameters-k-and-\\alpha">Selection of the parameters <span>$k$</span> and <span>$\alpha$</span></a><a id="Selection-of-the-parameters-k-and-\\alpha-1"></a><a class="docs-heading-anchor-permalink" href="#Selection-of-the-parameters-k-and-\\alpha" title="Permalink"></a></h2><p>We still use the dataset <code>x</code>.</p><pre><code class="language-julia hljs">vect_k = collect(1:5)
vect_alpha = sort([((0:2)./50)...,((1:4)./5)...])

params_risks = select_parameters_nonincreasing(rng, vect_k, vect_alpha, x, poisson, maxiter, nstart)

plot(; title = &quot;select parameters&quot;)
for (i,k) in enumerate(vect_k)
   plot!( vect_alpha, params_risks[i, :], label =&quot;k=$k&quot;, markershape = :circle )
end
xlabel!(&quot;alpha&quot;)
ylabel!(&quot;NMI&quot;)</code></pre><img src="d04392c4.svg" alt="Example block output"/><p>According to the graph, the risk decreases from 1 to 2 clusters, and as well from 2 to 3 clusters. However, there is no gain in terms of risk from 3 to 4 clusters or from 4 to 5 clusters. Indeed, the curves with parameters <span>$k = 3$</span>, <span>$k = 4$</span> and <span>$k = 5$</span> are very close. So we will cluster the data into <span>$k = 3$</span> clusters.</p><p>The curve with parameter <span>$k = 3$</span> strongly decreases, with a slope that is stable around <span>$\alpha = 0.04$</span>.</p><p>For more details about the selection of the parameter <span>$\alpha$</span>, we may focus on the curve <span>$k = 3$</span>. We may increase the <code>nstart</code> parameter and focus on small values of <span>$\alpha$</span>.</p><pre><code class="language-julia hljs">vect_k = [3]
vec_alpha = collect(0:15) ./ 200
params_risks = select_parameters_nonincreasing(rng, [3], vec_alpha, x, poisson, maxiter, 5)

plot(vec_alpha, params_risks[1, :], markershape = :circle)</code></pre><img src="7c545d7a.svg" alt="Example block output"/><p>There is no strong modification of the slope. Although the slope is stable after <span>$\alpha = 0.03$</span>. Therefore, we select the parameter <span>$\alpha = 0.03$</span>.</p><p>The clustering obtained with parameters <code>k</code> and <code>alpha</code> selected according to the heuristic is the following.</p><pre><code class="language-julia hljs">k, alpha = 3, 0.03
tb_poisson = trimmed_bregman_clustering( rng, x, k, alpha, poisson, maxiter, nstart )
tb_poisson.centers</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">1×3 Matrix{Float64}:
 41.0419  20.6136  9.57292</code></pre><pre><code class="language-julia hljs">plot( tb_poisson )</code></pre><img src="8c751e62.svg" alt="Example block output"/></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../trimmed-bregman/">« Bregman divergences</a><a class="docs-footer-nextpage" href="../poisson2/">Two-dimensional data from the Poisson distribution »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.5.0 on <span class="colophon-date" title="Tuesday 23 July 2024 09:11">Tuesday 23 July 2024</span>. Using Julia version 1.10.4.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
