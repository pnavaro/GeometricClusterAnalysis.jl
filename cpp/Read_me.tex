\documentclass[10pt,a4paper,notitlepage]{article}
\usepackage[utf8]{inputenc}
\usepackage[french]{babel}
\usepackage[T1]{fontenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}

\usepackage{tcolorbox}

\usepackage{geometry} \geometry{hmargin=2.5cm,vmargin=1.5cm}

\author{Claire Brécheteau}
\title{Read me - Programme kPLM}

\usepackage{bbm}
\newcommand{\R}{\mathbbm{R}}

\begin{document}
\maketitle

\abstract{

La k-PLM est une méthode de type partitionnement de données. On dispose d'un nuage de points dans $\R^d$. Notre but est de donner à chaque point une étiquette. Les points de même étiquette sont considérés comme appartenant à un même groupe.

Dans notre cas, notre méthode est du même type que l'algorithme des $k$-means. C'est-à-dire qu'il y a $k$ groupes (donc $k$ étiquettes différentes : de 1 à $k$). \`A chaque groupe est associé un centre. L'étiquette de chaque point correspond au groupe dont le centre est le plus proche du point, pour une certaine distance. Les centres sont régulièrement mis à jour, en fonction des points présents dans le groupe associé.}

\section{Les fichiers dans include}

Le fichier \texttt{kPLM{\_}algo.h} est le fichier appelé par le fichier principal \texttt{main.cpp}, il fait lui-même appel aux 4 fichiers d'extension \texttt{.h}, contenant les classes, situés dans le dossier \texttt{kPLM}.\\

Pour compiler le fichier \texttt{main.cpp} :

\fbox{\texttt{g++ main.cpp -o ./a.out -I ../../../../../../../../../usr/include/eigen3/}}\\

Pour exécuter le fichier \texttt{a.out} :

\fbox{\texttt{./a.out ../data/data\_symb.csv}}\\


L'affichage est le suivant :

\begin{tcolorbox}
The parameters of the algorithm are:\\
method = 0\\
k = 50\\
q = 20\\
n\_signal = 1000\\
n\_starts = 10\\
epochs = 20\\
d\_intrinsic = 2\\
sigma2\_min = 0.01\\
sigma2\_max = 0.01\\
lambda\_min = 0.01\\
lambda\_max = 100\\
normalized\_det = 0\\
The number of points for the algorithm is:1500\\

The first five points of the algorithm are:\\
1.51817, -1.20943\\
0.748019, -0.645651\\
-2.91832, -0.950895\\
1.64785, 1.11451\\
2.16077, 0.829922\\

Algorithm with non increasing intrinsic dimension : \\
6
5
4
3
2
1
0
6
5
4
3
2
1
0
6
5
4
3
2
1
0
6
5
4
3
2
1
0
6
5
4
3
2
1
0
6
5
4
3
2
1
0
6
5
4
3
2
1
0
6
5
4
3
2
1
0
6
5
4
3
2
1
0
6
5
4
3
2
1
0\\
-6237.67\\
-6278.32\\
-6280.87\\
-6280.48\\
-6280.48\\
-6280.48\\
-6280.48
\end{tcolorbox}

\begin{enumerate}
\item
Les paramètres affichés sont écrits dans le fichier \texttt{main.cpp}, mais il est tout à fait possible de modifier le fichier de sorte à ce qu'ils ne soient pas connus à la compilation, et donnés par l'utilisateur à l'exécution.\\

\textbf{ATTENTION : la dimension des données $d$ doit être connue à la compilation !}
\item
Les deux premières coordonnées des cinq premiers points des données sont ensuite affichées
\item
L'algorithme kPLM est lancé, pour une dimension intrinsèque variant entre 6 et 0...{color{red} Bizarre vu que nos données sont de dimension 2 ! Revoir}
\end{enumerate}

Les fonctions font appel à la librairie \texttt{Eigen}.



\subsection{Point.h}

Un élément de classe Point est un point du nuage de points à partitionner.

Il contient : les coordonnées du point, son étiquette, la distance au centre le plus proche, et l'étiquette et la distance au centre optimal pour la meilleure tentative, car l'algorithme de partitionnement est potentiellement répété plusieurs fois, on garde la tentative pour laquelle la somme des coûts sur tous les points du nuage est minimale.


{\color{red} Attention, les attributs privés sont notés publics pour l'instant, à modifier, et modifier le reste en conséquence}
\subsubsection{Classes amies}
\begin{enumerate}
\item \texttt{Centroid<d>;}
\item \texttt{kPLM<d>;}
\end{enumerate}
\subsubsection{Attributs privés}
\begin{enumerate}
\item \texttt{Matrix<double,1,d> X;} Coordonnées du point
\item \texttt{size\_t cluster;} Numéro de la cellule (ou du centre) à laquelle (auquel) ce point est associé. Initialement \texttt{cluster = 0}. Sa valeur est modifiée dans les méthodes des classes amies.
\item \texttt{double minDist;} Distance au centre le plus proche pour le coût souhaité \textit{(dans le cas de la k-PLM : norme de mahalanobis au carré entre le point et le paramètre \texttt{m} (du centre) (pour la matrice l'inverse de \texttt{Sigma\_inv} du centre) + \texttt{v} (du centre))}. Infini par défaut.
\item \texttt{size\_t opt\_cluster;} Numéro de la cellule pour la meilleure tentative : celle pour laquelle la somme des coûts  \texttt{minDist} de tous les échantillons est la plus faible.
\item \texttt{double opt\_minDist;} Coût pour la meilleure tentative.
\end{enumerate}
\subsubsection{Constructeurs}
Les arguments des constructeurs sont : vide, \texttt{const double (\&tab)[d]} ou \texttt{const Matrix<double,1,d> \& tab}.
\begin{itemize}
\item Les attributs \texttt{cluster} et \texttt{opt\_cluster} sont mis à 0.
\item Les attributs \texttt{minDist} et \texttt{opt\_minDist} sont mis à \texttt{\_\_DBL\_MAX\_\_}.
\item L'attribut \texttt{X} est soit la matrice avec que des 0, ou la matrice \texttt{tab}, en fonction du constructeur appelé.
\end{itemize}
\subsubsection{Attributs publics}
\begin{enumerate}
\item \texttt{get\_X} Pour récupérer les coordonnées \texttt{X} du point qui sont privées.
\end{enumerate}
\subsubsection{Fonctions amies}
Les deux fonctions suivantes ont la même fonction : calculer la moyenne et la matrice de covariance d'un sous-ensemble d'un nuage de points. L'une utilise un vecteur de Points, l'autre une matrice qui contient les coordonnées des points du nuage.

{\color{red} Pour l'instant, je ne sais pas encore s'il est plus rapide d'utiliser l'une ou l'autre, tout dépend de comment sera codée la méthode de partitionnement.}

\begin{enumerate}
\item \texttt{std::pair<Matrix<double,1,d>, Matrix<double,d,d>> calcul\_mean\_cov<d>(const std::vector<Point<d>> \& points, const std::vector<size\_t> \& indices);} Calcule la moyenne et la matrice de covariance des points \texttt{points} dont l'indice est dans \texttt{indices}.
\item \texttt{std::pair<Matrix<double,1,d>, Matrix<double,d,d>> calcul\_mean\_cov<d>(const Matrix<double,Dynamic,d> \& block\_points, const std::vector<size\_t> \& indices);}  Calcule la moyenne et la matrice de covariance du nuage de points \texttt{block\_points} dont l'indice est dans \texttt{indices}.
\end{enumerate}
\subsubsection{Autres fonctions}
\begin{enumerate}
\item \texttt{vector<Point<d>> readcsv(char* adresse)} lit des points dans un document et créer le vecteur de points correspondant.
\end{enumerate}

\subsection{Sigma\_inverted.h}

Un élément de classe \texttt{Sigma\_inverted} est l'inverse d'une matrice carrée symétrique réelle positive de taille $d\times d$, où $d$ est la dimension des points.

Dans notre algorithme de partitionnement, on associera à chaque centre, une matrice, donc un élément de type \texttt{Sigma\_inverted}. Cette matrice sera utilisée pour calculer la distance. On utilisera des normes de Mahalanobis (qui dépendent donc de la matrice) plutôt que des normes Euclidiennes, comme c'est le cas des k-means.

\subsubsection{Classes amies}
\begin{enumerate}
\item \texttt{Centroid<d>;}
\item \texttt{kPLM<d>;}
\end{enumerate}
\subsubsection{Attributs privés}
\begin{enumerate}
\item \texttt{Matrix<double,d,1> Eigenvalues\_inverted\_initial;} contient les inverses des valeurs propres, les valeurs propres sont en ordre croissant. Ce sont les valeurs propres de la matrice calculée à partir des points dans la cellule et les plus proches voisins du centre pour la distance tordue.
\item \texttt{Matrix<double,d,1> Eigenvalues\_inverted\_to\_use;} ce sont les valeurs propres calculées à partir de \texttt{Eigenvalues\_inverted\_initial}, modifiées en fonction de la méthode souhaitée (déterminant constant égal à 1, ou valeurs propres tronquées, ou certaines valeurs propres égales...). Ce sont ces valeurs propres qui sont utilisées dans la suite de l'algorithme.
\item \texttt{Matrix<double,d,d> Eigenvectors;} Les vecteurs propres de la matrice, calculés à partir des points dans la cellule et les plus proches voisins du centre pour la distance tordue.
\end{enumerate}
\subsubsection{Constructeurs}
Il existe un constructeur qui copie les attributs d'un objet de type \texttt{Sigma\_inverted}. Sinon,
\begin{itemize}
\item \texttt{Eigenvalues\_inverted\_initial} et \texttt{Eigenvalues\_inverted\_to\_use} sont des vecteurs avec que des 1, ou quand c'est précisé, sont égaux à \texttt{Eigenvalues\_inverted}.
\item \texttt{Eigenvectors} vaut la matrice identité, sauf quand \texttt{Eigenvectors} est donné.
\end{itemize}
\subsubsection{Attributs publics}
\begin{enumerate}
\item
\end{enumerate}

\subsection{Centroid.h}
Les $k$ centres de l'algorithme de partitionnement sont $k$ éléments de type \texttt{Centroid}.


\subsubsection{Classes amies}
\begin{enumerate}
\item \texttt{kPLM<d>;}
\end{enumerate}
\subsubsection{Attributs privés}
\begin{enumerate}
\item \texttt{Matrix<double,1,d> X;} : Coordonnées du centre. (Dans l'algorithme de la k-PLM (similaire à k-means), il s'agit de la moyenne des points de la cellule de Voronoï tordue par le critère) auquel le centre est associé.
\item \texttt{std::vector<size\_t> Voronoi\_points\_indices;} Indices des points de la cellule de Voronoï tordue. Important pour mettre à jour \texttt{X} et la matrice \texttt{Sigma\_inv}.
\item \texttt{Sigma\_inverted<d> Sigma\_inv;} Inverse de la matrice associée au centre.
\item \texttt{Matrix<double,1,d> m;} Moyenne des \texttt{q} plus proches voisins de \texttt{X} pour la norme de Mahalanobis associée à la matrice inverse de \texttt{Sigma\_inv}, dans un nuage de points \texttt{block} (mis à jour avec la fonction \texttt{update\_m\_v}).
\item \texttt{double v;} Variance (pour la norme de Mahalanobis associée à la matrice inverse de \texttt{Sigma\_inv}) des \texttt{q} plus proches voisins de \texttt{X} pour la norme de Mahalanobis associée à la matrice inverse de \texttt{Sigma\_inv} - log(det(\texttt{Sigma\_inv}))
\item \texttt{bool active;} Indique si la cellule de Voronoï associée au centre est non vide. \texttt{true} par défaut. Le centre n'a plus d'intérêt lorsque active vaut \texttt{false}.
\end{enumerate}
\subsubsection{Constructeurs}
\subsubsection{Attributs publics}
\begin{enumerate}
\item
\end{enumerate}

\subsection{kPLM.h}

Il s'agit de l'algorithme de partitionnement de données.

\subsubsection{Attributs privés}
\begin{enumerate}
\item \texttt{size\_t method;}
\begin{itemize}
\item \texttt{method} = 0 : on ne modifie pas les valeurs propres
\item \texttt{method} = 1 : on tronque les valeurs propres 
\item \texttt{method} = 2 : on tronque les valeurs propres avec les plus petites valeurs égales à une valeur propre donnée.
\item \texttt{method} = 3 : on renormalise les matrices pour qu'elles soient de déterminant égal à 1.
\end{itemize}
\item \texttt{std::vector<Point<d>>} points;
\item \texttt{Matrix<double,Dynamic,d>} block; 
\item \texttt{std::vector<Centroid<d>>} initial\_centroids;
\item \texttt{size\_t k;} Nombre de centres initial.
\item \texttt{size\_t q;} Nombre de plus proches voisins.
\item \texttt{size\_t n\_signal;} Nombre de points du nuage de points considérés comme du signal, les autres sont considérés comme des données aberrantes. 
\item \texttt{size\_t n\_starts;} Nombre d'initialisations différentes de l'algorithme, en gros, nombre de fois où on lance l'algorithme.
\item \texttt{size\_t epochs;} Nombre d'itérations de l'algorithme.
\item \texttt{size\_t d\_intrinsic;} Entier compris entre 0 et $d$. Pour chacune des $k$ matrices, les $d-d\_intrinsic$ plus petites valeurs propres doivent être égales. (Cette valeur peut différer d'une matrice à l'autre)
\item \texttt{double sigma2\_min;} Les plus petites valeurs propres sont supérieures à cette valeur.
\item \texttt{double sigma2\_max;} Les $d-d\_intrinsic$ plus petites valeurs propres sont inférieures à cette valeur.
\item \texttt{double lambda\_min;} Les $d\_intrinsic$ plus grandes valeurs propres sont supérieures à cette valeur.
\item \texttt{double lambda\_max;} Les $d\_intrinsic$ plus grandes valeurs propres sont inférieures à cette valeur.
\item \texttt{bool normalized\_det;} Vaut $1$ si le déterminant des matrices doit être égal à 1, 0 si aucune normalisation sur les matrices doit être effectuée.
\item \texttt{std::vector<Centroid<d>> optimal\_centroids;} 
\item \texttt{std::vector<size\_t> optimal\_labels;}
\item \texttt{std::vector<double> optimal\_costs;}
\item \texttt{double optimal\_cost;}
\item \texttt{bool optimisation\_done;}
\end{enumerate}
\subsubsection{Constructeurs}
\subsubsection{Attributs publics}
\begin{enumerate}
\item
\end{enumerate}

\section{Les fichiers dans test}

Pour chacun des fichiers .cpp suivants, le fichier exécutable correspondant est du même nom avec l'extension .out, et la sortie a été enregistrée dans le fichier de même nom avec l'extension \_output.\\

Par exemple, pour lancer un des fichier .cpp, pour recréer le fichier .out, on utilise la commande :

\fbox{\texttt{g++ basic{\_}centroid.cpp -o ./basic{\_}centroid.out -I ../../../../../../../../usr/include/eigen3/}}\\

\textbf{Attention, cela nécessite d'avoir installé le package \texttt{eigen3} dans le dossier \texttt{usr/include} et le nombre de \texttt{../} dépend de l'emplacement des fichiers.}\\

Pour avoir la sortie telle que celle enregistrée dans le document d'extension \_output, on utilise la commande :

\fbox{\texttt{./basic{\_}centroid.out ../data/data{\_}dim6.csv}}

\subsection{basic\_centroid.cpp}
\subsection{basic\_centroid\_trunc\_eigenvalues.cpp}
\subsection{compute\_PLM\_values.cpp}
\subsection{mahalanobis\_methods.cpp}
\subsection{read\_points\_compute\_mean\_cov.cpp}
\subsection{transform\_covariance\_matrix\_compute\_Mahalanobis.cpp}
\subsection{transform\_covariance\_matrix\_compute\_Mahalanobis\_nodata.cpp}

\section{Les fichiers dans doc}

Le fichier \texttt{intro\_kPLM.h} est juste une copie d'un fichier de documentation de code dans Gudhi, pour avoir une idée vague de comment commenter le code.
A remplir plus tard.

\section{Les fichiers dans examples}

Aucun pour l'instant.

\section{Les fichiers dans build}

Aucun.

\section{Les fichiers dans data}

Ce sont des fichiers .csv de données simulées.

\subsubsection{data.csv}
60 points dans $\R^2$ :

Trois petits groupes dont deux collés, avec quelques points aberrants.

\subsubsection{data\_symb.csv}
1500 points dans $\R^2$ :

Les 1000 premiers sont générés sur le symbole infini, avec du bruit gaussien dans $\R^2$, les 500 autres sont générés uniformément dans un rectangle contenant le symbole infini.

\subsubsection{data\_dim6.csv}
550 points dans $\R^6$ :

Les 500 premiers sont générés sur le symbole infini dans $\R^2\times\{0\}^4$, avec un bruit gaussien dans $\R^6$, les 50 autres sont générés uniformément dans un hypercube contenant le symbole infini.

\end{document}