var documenterSearchIndex = {"docs":
[{"location":"functions/#Functions","page":"Functions","title":"Functions","text":"","category":"section"},{"location":"functions/","page":"Functions","title":"Functions","text":"Modules = [GeometricClusterAnalysis]\nOrder   = [:function]","category":"page"},{"location":"functions/#GeometricClusterAnalysis.build_matrix-Tuple{Any}","page":"Functions","title":"GeometricClusterAnalysis.build_matrix","text":"build_matrix(result; indexed_by_r2 = true)\n\nDistance matrix for the graph filtration\n\nindexedbyr2 = true always work \nindexedbyr2 = false requires elements of weigths to be non-negative.\nindexedbyr2 = false for the sub-level set of the square-root of non-negative power functions : the k-PDTM or the k-PLM (when determinant of matrices are forced to be 1)\n\n\n\n\n\n","category":"method"},{"location":"functions/#GeometricClusterAnalysis.colorize!-NTuple{8, Any}","page":"Functions","title":"GeometricClusterAnalysis.colorize!","text":"colorize!( colors, μ, weights, points, k, signal, centers, Σ)\n\nFonction auxiliaire qui, étant donnés k centres, calcule les \"nouvelles  distances tordues\" de tous les points de P, à tous les centres On colorie de la couleur du centre le plus proche. La \"distance\" à un centre est le carré de la norme de Mahalanobis à la moyenne  locale \"mean\" autour du centre + un poids qui dépend d'une variance locale autour  du centre auquel on ajoute le log(det(Σ))\n\nOn utilise souvent la fonction mahalanobis. mahalanobis(P,c,Σ) calcule le carré de la norme de Mahalanobis  (p-c)^T Σ^{-1}(p-c), pour tout point p, ligne de P. C'est bien le carré ;  par ailleurs la fonction inverse la matrice Σ ;  on peut décider de lui passer l'inverse de la matrice Σ,  en ajoutant \"inverted = true\".\n\n\n\n\n\n","category":"method"},{"location":"functions/#GeometricClusterAnalysis.hierarchical_clustering_lem-Tuple{Any}","page":"Functions","title":"GeometricClusterAnalysis.hierarchical_clustering_lem","text":"matricehauteur : ``(r{i,j}){i,j} r{i,j} timerwhen componentsiandj`` merge\nr_ii : birth time of component i.\nc : number of components\nStop : components whose lifetime is larger than Stop never die\nSeuil : centers born after Seuil are removed\nIt is possible to select Stop and Seuil after running the algorithm with Stop = Inf and Seuil = Inf\nFor this, we look at the persistence diagram of the components : (x-axis Birth ; y-axis Death)\nstoreallcolors = TRUE : in the list Couleurs, we store all configurations of colors, for every step.\nThresholding\n\n\n\n\n\n","category":"method"},{"location":"functions/#GeometricClusterAnalysis.mahalanobis-Tuple{Matrix{Float64}, Vector{Float64}, Matrix{Float64}}","page":"Functions","title":"GeometricClusterAnalysis.mahalanobis","text":"mahalanobis( x, μ, Σ; inverted = false)\n\nReturns the squared Mahalanobis distance of all rows in x and the vector  μ = center with respect to Σ = cov. This is (for vector x) defined as\n\nD^2 = (x - mu) Sigma^-1 (x - mu)\n\nx : vector or matrix of data with, say, p columns.\nμ : mean vector of the distribution or second data vector of length p or recyclable to that length.\nΣ : covariance matrix p x p of the distribution.\ninverted : If true, Σ is supposed to contain the inverse of the covariance matrix.\n\n\n\n\n\n","category":"method"},{"location":"functions/#GeometricClusterAnalysis.noisy_three_curves-NTuple{5, Any}","page":"Functions","title":"GeometricClusterAnalysis.noisy_three_curves","text":"noisy_three_curves(npoints, nnoise, sigma, d)\n\nnsignal : number of signal points\nnnoise : number of additionnal outliers \n\nSignal points are x = y+z with\n\ny uniform on the 3 curves\nz normal with mean 0 and covariance matrix sigma * I_d (with I_d the identity matrix of R^d)\n\nd is the dimension of the data and sigma, the standard deviation of the additive Gaussian noise. When d2 y_i = 0 for i=2; with the notation y=(y_i)_i=1d\n\n\n\n\n\n","category":"method"},{"location":"functions/#GeometricClusterAnalysis.plot_ellipsoids-NTuple{5, Any}","page":"Functions","title":"GeometricClusterAnalysis.plot_ellipsoids","text":"P a matrix with 2 columns.\n\ncolorisnumeric = true if color contains numerical values. (the colors of points are given by these values)\ncolorisnumeric = false if color contains integers : the cluster's label. (the points are colored according to their cluster)\n\nThis corresponds to the SUBLEVEL SET f^-1(alpha) of the function\n\n  fx rightarrow min_i = 1c ( x-centers_i^2_Sigma_i + weights_i )\n\nwith x^2_Sigma = x^T Sigma^-1 x, the squared Mahalanobis norm of x.\n\nfill = TRUE : ellipses are filled with the proper color\ncenters : matrix of size cx2\nalpha : a numeric\nweights : vector of numerics of size c\nSigma : list of c 2x2-matrices\n\nThe ellipses are directed by the eigenvectors of the matrices in Sigma, with :\n\nsemi-major axis : sqrt(beta*v1)\nsemi-minor axis : sqrt(beta*v2)\nwith v1 and v2 the largest and smallest eigenvalues of the matrices in Sigma\nbeta = the positive part of alpha - weights\n\n\n\n\n\n","category":"method"},{"location":"functions/#GeometricClusterAnalysis.return_color-Tuple{Any, Any, Any}","page":"Functions","title":"GeometricClusterAnalysis.return_color","text":"return_color(centre, couleurs, Indices_depart)\n\ncentre : vector of integers such that centre[i] is the label of the center associated to the i-th point\ncouleurs[1] : label of the center that is born first, i.e. for the Indice_depart[1]-th center\n\n\n\n\n\n","category":"method"},{"location":"fake_data/#Fake-datasets","page":"Datasets","title":"Fake datasets","text":"","category":"section"},{"location":"fake_data/#Three-curves","page":"Datasets","title":"Three curves","text":"","category":"section"},{"location":"fake_data/","page":"Datasets","title":"Datasets","text":"using Random\nusing Plots\nusing GeometricClusterAnalysis\n\nnsignal = 500 # number of signal points\nnnoise = 200 # number of outliers\ndim = 2 # dimension of the data\nsigma = 0.02 # standard deviation for the additive noise\n\nrng = MersenneTwister(1234)\n\ndataset = noisy_three_curves( rng, nsignal, nnoise, sigma, dim)\n\nplot(dataset, palette = :rainbow)","category":"page"},{"location":"fake_data/#Infinity-symbol","page":"Datasets","title":"Infinity symbol","text":"","category":"section"},{"location":"fake_data/","page":"Datasets","title":"Datasets","text":"\nsignal = 500 \nnoise = 50\nσ = 0.05\ndimension = 3\nnoise_min = -5\nnoise_max = 5\n\ndataset = infinity_symbol(rng, signal, noise, σ, dimension, noise_min, noise_max)\n\nplot(dataset)","category":"page"},{"location":"#GeometricClusterAnalysis.jl","page":"Documentation","title":"GeometricClusterAnalysis.jl","text":"","category":"section"},{"location":"","page":"Documentation","title":"Documentation","text":"Documentation for GeometricClusterAnalysis.jl","category":"page"},{"location":"","page":"Documentation","title":"Documentation","text":"","category":"page"},{"location":"three_curves/#The-Three-Curves-example","page":"Three Curves","title":"The Three-Curves example","text":"","category":"section"},{"location":"three_curves/","page":"Three Curves","title":"Three Curves","text":"\nusing GeometricClusterAnalysis\nusing LinearAlgebra\nusing Plots\nusing Random\nusing Statistics\n","category":"page"},{"location":"three_curves/#Generate-the-dataset","page":"Three Curves","title":"Generate the dataset","text":"","category":"section"},{"location":"three_curves/","page":"Three Curves","title":"Three Curves","text":"Let's generate a set of points that draws three curves with a different label.","category":"page"},{"location":"three_curves/","page":"Three Curves","title":"Three Curves","text":"nsignal = 500    # number of signal points\nnnoise = 200     # number of outliers\ndim = 2          # dimension of the data\nsigma = 0.02     # standard deviation for the additive noise\nnb_clusters = 3  # number of clusters\nk = 10           # number of nearest neighbors\nc = 50           # number of ellipsoids\niter_max = 100   # maximum number of iterations of the algorithm kPLM\nnstart = 10      # number of initializations of the algorithm kPLM\n\nrng = MersenneTwister(1234)\n\ndata = noisy_three_curves(rng, nsignal, nnoise, sigma, dim)\n\nplot(data)","category":"page"},{"location":"three_curves/#Hierarchical-clustering","page":"Three Curves","title":"Hierarchical clustering","text":"","category":"section"},{"location":"three_curves/","page":"Three Curves","title":"Three Curves","text":"function f_Σ!(Σ) end\n\ndist_func = kplm(rng, data.points, k, c, nsignal, iter_max, nstart, f_Σ!)\n\nmh = build_matrix(dist_func)\n\nhc1 = hierarchical_clustering_lem(mh)\n\nnb_means_removed = 5 \n\nlengthn = length(hc1.Naissance)\n\nif nb_means_removed > 0\n    Seuil = mean((hc1.Naissance[lengthn - nb_means_removed],hc1.Naissance[lengthn - nb_means_removed + 1]))\nelse\n  Seuil = Inf\nend\n\nhc2 = hierarchical_clustering_lem(mh, Stop = Inf, Seuil = Seuil)\n\nbd = plot_birth_death(hc2, lim_min = -15, lim_max = 10, filename = \"persistence_diagram2\")\n\nsort!(bd)\nlengthbd = length(bd)\nStop = mean((bd[lengthbd - nb_clusters],bd[lengthbd - nb_clusters + 1]))\n\nsp_hc = hierarchical_clustering_lem(mh; Stop = Stop, Seuil = Seuil)\n\ncolor_final = color_points_from_centers( data.points, k, nsignal, dist_func, sp_hc)\n\nremain_indices = sp_hc.Indices_depart\n\np = plot_ellipsoids(data, remain_indices, color_final, dist_func, 0 )\n\np","category":"page"},{"location":"types/#Types","page":"Types","title":"Types","text":"","category":"section"},{"location":"types/","page":"Types","title":"Types","text":"Modules = [GeometricClusterAnalysis]\nOrder   = [:type]","category":"page"},{"location":"types/#GeometricClusterAnalysis.KplmResult","page":"Types","title":"GeometricClusterAnalysis.KplmResult","text":"KplmResult\n\nObject resulting from kplm algorithm that contains the number of clusters,  centroids, means, weights, covariance matrices, costs\n\n\n\n\n\n","category":"type"}]
}
