<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Two-dimensional data from the Poisson distribution · GeometricClusterAnalysis.jl</title><meta name="title" content="Two-dimensional data from the Poisson distribution · GeometricClusterAnalysis.jl"/><meta property="og:title" content="Two-dimensional data from the Poisson distribution · GeometricClusterAnalysis.jl"/><meta property="twitter:title" content="Two-dimensional data from the Poisson distribution · GeometricClusterAnalysis.jl"/><meta name="description" content="Documentation for GeometricClusterAnalysis.jl."/><meta property="og:description" content="Documentation for GeometricClusterAnalysis.jl."/><meta property="twitter:description" content="Documentation for GeometricClusterAnalysis.jl."/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img src="../assets/logo.png" alt="GeometricClusterAnalysis.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../">GeometricClusterAnalysis.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Documentation</a></li><li><a class="tocitem" href="../fake_data/">Datasets</a></li><li><a class="tocitem" href="../fleas/">Fleas dataset</a></li><li><a class="tocitem" href="../three_curves/">Three Curves</a></li><li><a class="tocitem" href="../two_spirals/">Two Spirals</a></li><li><a class="tocitem" href="../fourteen_lines/">Fourteen lines</a></li><li><span class="tocitem">Trimmed Bregman Clustering</span><ul><li><a class="tocitem" href="../trimmed-bregman/">Bregman divergences</a></li><li><a class="tocitem" href="../poisson1/">One-dimensional data from the Poisson distribution</a></li><li class="is-active"><a class="tocitem" href>Two-dimensional data from the Poisson distribution</a><ul class="internal"><li><a class="tocitem" href="#Generation-of-variables-from-a-mixture-of-Poisson-distributions"><span>Generation of variables from a mixture of Poisson distributions</span></a></li><li><a class="tocitem" href="#Data-clustering-on-an-example"><span>Data clustering on an example</span></a></li><li><a class="tocitem" href="#Using-the-classical-algorithm-:-Trimmed-k-means"><span>Using the classical algorithm : Trimmed <span>$k$</span>-means</span></a></li><li><a class="tocitem" href="#Bregman-divergence-selection-for-the-Poisson-distribution"><span>Bregman divergence selection for the Poisson distribution</span></a></li><li><a class="tocitem" href="#Performance-comparison"><span>Performance comparison</span></a></li><li><a class="tocitem" href="#Performance-measurement"><span>Performance measurement</span></a></li><li><a class="tocitem" href="#Selection-of-the-parameters-k-and-\\alpha"><span>Selection of the parameters <span>$k$</span> and <span>$\alpha$</span></span></a></li></ul></li><li><a class="tocitem" href="../obama/">Application to authors texts clustering</a></li></ul></li><li><a class="tocitem" href="../dtm/">Robust approximations of compact sets</a></li><li><a class="tocitem" href="../types/">Types</a></li><li><a class="tocitem" href="../functions/">Functions</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Trimmed Bregman Clustering</a></li><li class="is-active"><a href>Two-dimensional data from the Poisson distribution</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Two-dimensional data from the Poisson distribution</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/pnavaro/GeometricClusterAnalysis.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/pnavaro/GeometricClusterAnalysis.jl/blob/master/docs/src/poisson2.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Two-dimensional-data-from-the-Poisson-distribution"><a class="docs-heading-anchor" href="#Two-dimensional-data-from-the-Poisson-distribution">Two-dimensional data from the Poisson distribution</a><a id="Two-dimensional-data-from-the-Poisson-distribution-1"></a><a class="docs-heading-anchor-permalink" href="#Two-dimensional-data-from-the-Poisson-distribution" title="Permalink"></a></h1><h2 id="Generation-of-variables-from-a-mixture-of-Poisson-distributions"><a class="docs-heading-anchor" href="#Generation-of-variables-from-a-mixture-of-Poisson-distributions">Generation of variables from a mixture of Poisson distributions</a><a id="Generation-of-variables-from-a-mixture-of-Poisson-distributions-1"></a><a class="docs-heading-anchor-permalink" href="#Generation-of-variables-from-a-mixture-of-Poisson-distributions" title="Permalink"></a></h2><p>We generate a second sample of 950 points in <span>$\mathcal{R}^2$</span>. The two coordinates of each point are independent. They are sampled according to a Poisson distribution with parameter  <span>$10$</span>, <span>$20$</span> or<span>$40$</span> (for every point, the parameter is chosen with probability <span>$\frac13$</span>). Then, a sample of 50 outliers is generated according to the Uniform distribution on <span>$[0,120]\times[0,120]$</span>. We denote by <code>x</code> the sample containing these 1000 points. </p><pre><code class="language-julia hljs">using GeometricClusterAnalysis
import GeometricClusterAnalysis: sample_poisson, sample_outliers, performance
using Plots
using Random

n = 1000
n_outliers = 50
d = 2

rng = MersenneTwister(1)
lambdas =  [10,20,40]
proba = [1/3,1/3,1/3]
points, labels = sample_poisson(rng, n - n_outliers, d, lambdas, proba)

outliers = sample_outliers(rng, n_outliers, d; scale = 120)
x = hcat(points, outliers)
labels_true = vcat(labels, zeros(Int, n_outliers))

scatter( x[1,:], x[2,:], c = labels_true, palette = :rainbow)</code></pre><img src="a5eb772c.svg" alt="Example block output"/><h2 id="Data-clustering-on-an-example"><a class="docs-heading-anchor" href="#Data-clustering-on-an-example">Data clustering on an example</a><a id="Data-clustering-on-an-example-1"></a><a class="docs-heading-anchor-permalink" href="#Data-clustering-on-an-example" title="Permalink"></a></h2><p>In order to cluster the data, we will use the following parameters.</p><pre><code class="language-julia hljs">k = 3
α = 0.03
maxiter = 50
nstart = 50</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">50</code></pre><h2 id="Using-the-classical-algorithm-:-Trimmed-k-means"><a class="docs-heading-anchor" href="#Using-the-classical-algorithm-:-Trimmed-k-means">Using the classical algorithm : Trimmed <span>$k$</span>-means</a><a id="Using-the-classical-algorithm-:-Trimmed-k-means-1"></a><a class="docs-heading-anchor-permalink" href="#Using-the-classical-algorithm-:-Trimmed-k-means" title="Permalink"></a></h2><p>(<a href="../references/#Cuesta-Albertos1997">Cuesta-Albertos <em>et al.</em>, 1997</a>)</p><p>Firstly, we use our algorithm <a href="../trimmed-bregman/#GeometricClusterAnalysis.trimmed_bregman_clustering"><code>trimmed_bregman_clustering</code></a>  with the squared Euclidean distance <code>euclidean</code>.</p><pre><code class="language-julia hljs">tb_kmeans = trimmed_bregman_clustering( rng, x, k, α, euclidean, maxiter, nstart )
println(&quot;k-means : $(tb_kmeans.centers)&quot;)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">k-means : [40.38294722784871 10.537657975809905 20.464713649163052; 40.354190104912355 10.271275601080664 20.829711544491296]</code></pre><p>We see three clusters with the same diameter. So, multiple outliers are assigned to a cluster of points associated to the mean <span>$(10,10)$</span>. This cluster was actually supposted to have a diameter smaller than for points generated from Poisson distributions with means <span>$(20,20)$</span> and <span>$(40,40)$</span>.</p><pre><code class="language-julia hljs">plot(tb_kmeans)</code></pre><img src="3506ee5f.svg" alt="Example block output"/><h2 id="Bregman-divergence-selection-for-the-Poisson-distribution"><a class="docs-heading-anchor" href="#Bregman-divergence-selection-for-the-Poisson-distribution">Bregman divergence selection for the Poisson distribution</a><a id="Bregman-divergence-selection-for-the-Poisson-distribution-1"></a><a class="docs-heading-anchor-permalink" href="#Bregman-divergence-selection-for-the-Poisson-distribution" title="Permalink"></a></h2><p>When using the Bregman divergence associated to the Poisson distribution, the clusters have various diameters. These diameters are well suited for the data. Moreover, the estimators <code>tB_Poisson$centers</code> of the means are better..</p><pre><code class="language-julia hljs">tb_poisson = trimmed_bregman_clustering( rng, x, k, α, poisson, maxiter, nstart )
println(&quot;poisson : $(tb_poisson.centers)&quot;)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">poisson : [20.126198864736047 10.324096110361406 40.33912028708773; 20.34891612932911 10.04219126366854 40.249302368137506]</code></pre><pre><code class="language-julia hljs">plot(tb_poisson)</code></pre><img src="ff48c2dd.svg" alt="Example block output"/><h2 id="Performance-comparison"><a class="docs-heading-anchor" href="#Performance-comparison">Performance comparison</a><a id="Performance-comparison-1"></a><a class="docs-heading-anchor-permalink" href="#Performance-comparison" title="Permalink"></a></h2><p>We measure the performance of the two clustering methods (with the squared Euclidean distance and with the Bregman divergence associated to the Poisson distribution), using the normalised mutual information (NMI).</p><pre><code class="language-julia hljs">import Clustering: mutualinfo
println(&quot;k-means : $(mutualinfo( tb_kmeans.cluster, labels_true, normed = true ))&quot;)
println(&quot;poisson : $(mutualinfo( tb_poisson.cluster, labels_true, normed = true ))&quot;)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">k-means : 0.8137090523241111
poisson : 0.8259135879044363</code></pre><p>The normalised mutual information is larger for the Bregman divergence associated to the Poisson distribution. This illustrates the fact that, for this example, using the correct divergence improves the clustering : the performance is better than for a classical trimmed <code>k</code>-means.</p><h2 id="Performance-measurement"><a class="docs-heading-anchor" href="#Performance-measurement">Performance measurement</a><a id="Performance-measurement-1"></a><a class="docs-heading-anchor-permalink" href="#Performance-measurement" title="Permalink"></a></h2><p>In order to ensure that the method with the correct Bregman divergence outperforms Trimmed <code>k</code>-means, we replicate the experiment <code>replications</code> times.</p><p>In particular, we replicate the algorithm <a href="../trimmed-bregman/#GeometricClusterAnalysis.trimmed_bregman_clustering"><code>trimmed_bregman_clustering</code></a>,  <code>replications</code> times, on samples of size <span>$n = 1000$</span>, on data generated according to the aforementionned procedure.</p><p>The function <a href="../functions/#GeometricClusterAnalysis.performance"><code>performance</code></a> does it.</p><pre><code class="language-julia hljs">sample_generator = (rng, n) -&gt; sample_poisson(rng, n, d, lambdas, proba)
outliers_generator = (rng, n) -&gt; sample_outliers(rng, n, d; scale = 120)

nmi_kmeans, _, _ = performance(n, n_outliers, k, α, sample_generator, outliers_generator, euclidean)
nmi_poisson, _, _ = performance(n, n_outliers, k, α, sample_generator, outliers_generator, poisson)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">([0.8356598819265075, 0.8522312505329743, 0.8591345518407613, 0.8610637292766185, 0.8745705543779904, 0.8617018594300161, 0.896725093980184, 0.8339466059687569, 0.8455702227968579, 0.8543486895823693  …  0.8425314667867644, 0.8252535684443999, 0.8517394503721635, 0.8517282945103648, 0.8403440272336288, 0.8618119879135011, 0.8505247390669495, 0.845877014737236, 0.8617574721117149, 0.8514048231924788], 0.8563155121836071, 0.0033341253272724507)</code></pre><p>The boxplots show the NMI on the two different methods. The method using the Bregman divergence associated to the Poisson distribution outperfoms the Trimmed <code>k</code>-means method.</p><pre><code class="language-julia hljs">using StatsPlots

boxplot( ones(100), nmi_kmeans, label = &quot;kmeans&quot; )
boxplot!( fill(2, 100), nmi_poisson, label = &quot;poisson&quot; )</code></pre><img src="ff2d5081.svg" alt="Example block output"/><h2 id="Selection-of-the-parameters-k-and-\\alpha"><a class="docs-heading-anchor" href="#Selection-of-the-parameters-k-and-\\alpha">Selection of the parameters <span>$k$</span> and <span>$\alpha$</span></a><a id="Selection-of-the-parameters-k-and-\\alpha-1"></a><a class="docs-heading-anchor-permalink" href="#Selection-of-the-parameters-k-and-\\alpha" title="Permalink"></a></h2><p>We still use the dataset <code>x</code>.</p><pre><code class="language-julia hljs">vect_k = collect(1:5)
vect_α = sort([((0:2)./50)...,((1:4)./5)...])

rng = MersenneTwister(42)
nstart = 5

params_risks = select_parameters_nonincreasing(rng, vect_k, vect_α, x, poisson, maxiter, nstart)

plot(; title = &quot;select parameters&quot;)
for (i,k) in enumerate(vect_k)
   plot!( vect_α, params_risks[i, :], label =&quot;k=$k&quot;, markershape = :circle )
end
xlabel!(&quot;alpha&quot;)
ylabel!(&quot;NMI&quot;)</code></pre><img src="4c7b244b.svg" alt="Example block output"/><p>According to the graph, the risk decreases from 1 to 2 clusters, and as well from 2 to 3 clusters. However, there is no gain in terms of risk from 3 to 4 clusters or from 4 to 5 clusters. Indeed, the curves with parameters <span>$k = 3$</span>, <span>$k = 4$</span> and <span>$k = 5$</span> are very close. So we will cluster the data into <span>$k = 3$</span> clusters.</p><p>The curve with parameter <span>$k = 3$</span> strongly decreases, with a slope that is stable around <span>$\alpha = 0.04$</span>.</p><p>For more details about the selection of the parameter <span>$\alpha$</span>, we may focus on the curve <span>$k = 3$</span>. We may increase the <code>nstart</code> parameter and focus on small values of <span>$\alpha$</span>.</p><pre><code class="language-julia hljs">vec_k = [3]
vec_α = collect(0:15) ./ 200
params_risks = select_parameters_nonincreasing(rng, vec_k, vec_α, x, poisson, maxiter, nstart)

plot(vec_α, params_risks[1, :], markershape = :circle)</code></pre><img src="3229055b.svg" alt="Example block output"/><p>There is no strong modification of the slope. Although the slope is stable after <span>$\alpha = 0.04$</span>. Therefore, we select the parameter <span>$\alpha = 0.04$</span>.</p><pre><code class="language-julia hljs">k, α = 3, 0.04
tb = trimmed_bregman_clustering( rng, x, k, α, poisson, maxiter, nstart )
plot(tb)</code></pre><img src="4696a896.svg" alt="Example block output"/></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../poisson1/">« One-dimensional data from the Poisson distribution</a><a class="docs-footer-nextpage" href="../obama/">Application to authors texts clustering »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.5.0 on <span class="colophon-date" title="Tuesday 23 July 2024 08:51">Tuesday 23 July 2024</span>. Using Julia version 1.10.4.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
